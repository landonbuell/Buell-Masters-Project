{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d51821",
   "metadata": {},
   "source": [
    "## Playing with PyTorch Models\n",
    "#### Landon Buell - June 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9998fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15274c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 16\n",
    "SAMPLE_SHAPE = (3,200,200)\n",
    "\n",
    "X = torch.zeros(size=((BATCH_SIZE,) + SAMPLE_SHAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e75146f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 200, 200])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a17279",
   "metadata": {},
   "source": [
    "#### Create some Torch Layers + Show Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29b8fd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 198, 198])\n"
     ]
    }
   ],
   "source": [
    "layer00 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(\n",
    "        in_channels=3,\n",
    "        out_channels=64,\n",
    "        kernel_size=(3,3),\n",
    "        stride=(1,1)),\n",
    "    torch.nn.ReLU())\n",
    "\n",
    "x0 = layer00(X)\n",
    "print(x0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e58f722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 196, 196])\n"
     ]
    }
   ],
   "source": [
    "layer01 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(\n",
    "        in_channels=64,\n",
    "        out_channels=64,\n",
    "        kernel_size=(3,3),\n",
    "        stride=(1,1)),\n",
    "    torch.nn.ReLU())\n",
    "\n",
    "x1 = layer01(x0)\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72a1ef30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 97, 97])\n"
     ]
    }
   ],
   "source": [
    "layer02 = torch.nn.Sequential(\n",
    "    torch.nn.MaxPool2d(\n",
    "        kernel_size=(3,3),\n",
    "        stride=(2,2)))\n",
    "\n",
    "x2 = layer02(x1)\n",
    "print(x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08501f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 95, 95])\n"
     ]
    }
   ],
   "source": [
    "layer03 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(\n",
    "        in_channels=64,\n",
    "        out_channels=64,\n",
    "        kernel_size=(3,3),\n",
    "        stride=(1,1)),\n",
    "    torch.nn.ReLU())\n",
    "\n",
    "x3 = layer03(x2)\n",
    "print(x3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c994b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 93, 93])\n"
     ]
    }
   ],
   "source": [
    "layer04 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(\n",
    "        in_channels=64,\n",
    "        out_channels=64,\n",
    "        kernel_size=(3,3),\n",
    "        stride=(1,1)),\n",
    "    torch.nn.ReLU())\n",
    "\n",
    "x4 = layer04(x3)\n",
    "print(x4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64727efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 46, 46])\n"
     ]
    }
   ],
   "source": [
    "layer05 = torch.nn.Sequential(\n",
    "    torch.nn.MaxPool2d(\n",
    "        kernel_size=(3,3),\n",
    "        stride=(2,2)))\n",
    "\n",
    "x5 = layer05(x4)\n",
    "print(x5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dafcd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 44, 44])\n"
     ]
    }
   ],
   "source": [
    "layer06 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(\n",
    "        in_channels=64,\n",
    "        out_channels=64,\n",
    "        kernel_size=(3,3),\n",
    "        stride=(1,1)),\n",
    "    torch.nn.ReLU())\n",
    "\n",
    "x6 = layer06(x5)\n",
    "print(x6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b90c37ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 42, 42])\n"
     ]
    }
   ],
   "source": [
    "layer07 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(\n",
    "        in_channels=64,\n",
    "        out_channels=64,\n",
    "        kernel_size=(3,3),\n",
    "        stride=(1,1)),\n",
    "    torch.nn.ReLU())\n",
    "\n",
    "x7 = layer07(x6)\n",
    "print(x7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "408be312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "layer08 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(\n",
    "        in_channels=64,\n",
    "        out_channels=64,\n",
    "        kernel_size=(3,3),\n",
    "        stride=(1,1)),\n",
    "    torch.nn.ReLU())\n",
    "\n",
    "x8 = layer08(x7)\n",
    "print(x8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90f468b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 19, 19])\n"
     ]
    }
   ],
   "source": [
    "layer09 = torch.nn.Sequential(\n",
    "    torch.nn.MaxPool2d(\n",
    "        kernel_size=(3,3),\n",
    "        stride=(2,2)))\n",
    "\n",
    "x9 = layer09(x8)\n",
    "print(x9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b56f278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23104])\n"
     ]
    }
   ],
   "source": [
    "layer10 = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(\n",
    "        start_dim=1,\n",
    "        end_dim=-1))\n",
    "\n",
    "x10 = layer10(x9)\n",
    "print(x10.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0374b729",
   "metadata": {},
   "source": [
    "#### Make a torch.nn.Module subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "301cca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InspiredVgg16(torch.nn.Module):\n",
    "    \"\"\" Class for a Model inspired by VGG-16 \"\"\"\n",
    "    \n",
    "    def __init__(self,numClasses: int):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self._numClasses = numClasses\n",
    "        self._layers  = [None] * 16\n",
    "        \n",
    "        self.__initLayerGroup01()\n",
    "        self.__initLayerGroup02()\n",
    "        self.__initLayerGroup03()\n",
    "        self.__initLayerGroup04()\n",
    "        self.__initDenseLayers()\n",
    "        \n",
    "    def __del__(self):\n",
    "        \"\"\" Destructor \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __initLayerGroup01(self):\n",
    "        \"\"\" Initialize Layer Chain \"\"\"\n",
    "        self._layers[0] = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=64,\n",
    "                kernel_size=(3,3),\n",
    "                stride=(1,1)),\n",
    "            torch.nn.ReLU())\n",
    "        self._layers[1] = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=64,\n",
    "                kernel_size=(3,3),\n",
    "                stride=(1,1)),\n",
    "            torch.nn.ReLU())\n",
    "        self._layers[2] = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(\n",
    "                kernel_size=(3,3),\n",
    "                stride=(2,2)))\n",
    "        return None\n",
    "    \n",
    "    def __initLayerGroup02(self):\n",
    "        \"\"\" Initialize Layer Chain \"\"\"\n",
    "        self._layers[3] = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=64,\n",
    "                kernel_size=(3,3),\n",
    "                stride=(1,1)),\n",
    "            torch.nn.ReLU())\n",
    "        self._layers[4] = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=64,\n",
    "                kernel_size=(3,3),\n",
    "                stride=(1,1)),\n",
    "            torch.nn.ReLU())\n",
    "        self._layers[5] = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(\n",
    "                kernel_size=(3,3),\n",
    "                stride=(2,2)))\n",
    "        return None\n",
    "    \n",
    "    def __initLayerGroup03(self):\n",
    "        \"\"\" Initialize Layer Chain \"\"\"\n",
    "        self._layers[6] = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=32,\n",
    "                kernel_size=(3,3),\n",
    "                stride=(1,1)),\n",
    "            torch.nn.ReLU())\n",
    "        self._layers[7] = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=32,\n",
    "                kernel_size=(3,3),\n",
    "                stride=(1,1)),\n",
    "            torch.nn.ReLU())\n",
    "        self._layers[8] = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(\n",
    "                kernel_size=(3,3),\n",
    "                stride=(2,2)))\n",
    "        return None\n",
    "    \n",
    "    def __initLayerGroup04(self):\n",
    "        \"\"\" Initialize Layer Chain \"\"\"\n",
    "        self._layers[9] = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=32,\n",
    "                kernel_size=(3,3),\n",
    "                stride=(1,1)),\n",
    "            torch.nn.ReLU())\n",
    "        self._layers[10] = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=32,\n",
    "                kernel_size=(3,3),\n",
    "                stride=(1,1)),\n",
    "            torch.nn.ReLU())\n",
    "        self._layers[11] = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(\n",
    "                kernel_size=(3,3),\n",
    "                stride=(1,1)))\n",
    "        return None\n",
    "    \n",
    "    def __initDenseLayers(self):\n",
    "        \"\"\" Initialize Dense Layers \"\"\"\n",
    "        self._layers[12] = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(\n",
    "                start_dim=1,\n",
    "                end_dim=-1))\n",
    "        self._layers[13] = torch.nn.Sequential(\n",
    "            torch.nn.Linear(\n",
    "                in_features=6272,\n",
    "                out_features=4096),\n",
    "            torch.nn.ReLU())\n",
    "        self._layers[13] = torch.nn.Sequential(\n",
    "            torch.nn.Linear(\n",
    "                in_features=4096,\n",
    "                out_features=2048),\n",
    "            torch.nn.ReLU())\n",
    "        self._layers[14] = torch.nn.Sequential(\n",
    "            torch.nn.Linear(\n",
    "                in_features=2048,\n",
    "                out_features=1024),\n",
    "            torch.nn.ReLU())\n",
    "        self._layers[15] = torch.nn.Sequential(\n",
    "            torch.nn.Linear(\n",
    "                in_features=1024,\n",
    "                out_features=self._numClasses),\n",
    "            torch.nn.Softmax())\n",
    "        return None\n",
    "    \n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Define Forward pass mechanism \"\"\"\n",
    "        x = torch.clone(inputs)\n",
    "        for ii,layer in enumerate(self._layers):\n",
    "            if (layer is None):\n",
    "                continue\n",
    "            x = layer(x)\n",
    "            msg = \"Layer {0}: Output Shape = {1}\".format(ii,x.shape)\n",
    "            print(msg)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e6b59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InspiredVgg16(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "42724d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: Output Shape = torch.Size([16, 64, 198, 198])\n",
      "Layer 1: Output Shape = torch.Size([16, 64, 196, 196])\n",
      "Layer 2: Output Shape = torch.Size([16, 64, 97, 97])\n",
      "Layer 3: Output Shape = torch.Size([16, 64, 95, 95])\n",
      "Layer 4: Output Shape = torch.Size([16, 64, 93, 93])\n",
      "Layer 5: Output Shape = torch.Size([16, 64, 46, 46])\n",
      "Layer 6: Output Shape = torch.Size([16, 32, 44, 44])\n",
      "Layer 7: Output Shape = torch.Size([16, 32, 42, 42])\n",
      "Layer 8: Output Shape = torch.Size([16, 32, 20, 20])\n",
      "Layer 9: Output Shape = torch.Size([16, 32, 18, 18])\n",
      "Layer 10: Output Shape = torch.Size([16, 32, 16, 16])\n",
      "Layer 11: Output Shape = torch.Size([16, 32, 14, 14])\n",
      "Layer 12: Output Shape = torch.Size([16, 6272])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x6272 and 4096x2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13684/1724297465.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13684/2677548779.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Layer {0}: Output Shape = {1}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x6272 and 4096x2048)"
     ]
    }
   ],
   "source": [
    "y = model.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70f806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
